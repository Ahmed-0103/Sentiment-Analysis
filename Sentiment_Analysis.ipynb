{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 47412,
     "status": "ok",
     "timestamp": 1746386385872,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "8HBY9x2XG-_G",
    "outputId": "b057e2c1-a866-4e1c-f082-c7e8be85f6ee"
   },
   "outputs": [],
   "source": [
    "!pip install contractions\n",
    "!pip install emoji\n",
    "!pip install datasets\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLl-F6ws_nPy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import spacy\n",
    "import emoji\n",
    "from contractions import fix as fix_contractions\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Input, Reshape\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, RobertaTokenizer, TFRobertaForSequenceClassification, create_optimizer\n",
    "from datasets import Dataset\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17385,
     "status": "ok",
     "timestamp": 1746386437071,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "4FUZWNaUX9zU",
    "outputId": "992eea91-796e-4098-af4b-a47081aaf665"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/Ahmed_Anas_20023579_CreativePiece/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S3HACoBEYT8D"
   },
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv('twitter.csv', encoding = 'latin-1', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SucAkfkWg7L"
   },
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv('reddit-train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1746119517587,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "01869296765867302633"
     },
     "user_tz": -60
    },
    "id": "R5CjzRzCW8dT",
    "outputId": "4768bf15-a85a-455c-ff1e-fdc4e0df63d4"
   },
   "outputs": [],
   "source": [
    "reddit_df.info()\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1746119517834,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "01869296765867302633"
     },
     "user_tz": -60
    },
    "id": "6uyeY2QxXOH6",
    "outputId": "854c002c-759c-4581-c782-9381fe5c7e77"
   },
   "outputs": [],
   "source": [
    "reddit_df.drop(columns=['author','subreddit','score', 'ups', 'downs', 'date', 'created_utc', 'parent_comment'], inplace=True)\n",
    "reddit_df.dropna(inplace=True)\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1746119517882,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "01869296765867302633"
     },
     "user_tz": -60
    },
    "id": "nV0s0u9S9uBM",
    "outputId": "97a57398-1442-43ae-8152-4745b73ea008"
   },
   "outputs": [],
   "source": [
    "reddit_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1746119518423,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "01869296765867302633"
     },
     "user_tz": -60
    },
    "id": "V7FsXVbqYeY4",
    "outputId": "1f93a69c-9b59-47f9-da7c-82bae36bd105"
   },
   "outputs": [],
   "source": [
    "twitter_df.info()\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1746119518785,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "01869296765867302633"
     },
     "user_tz": -60
    },
    "id": "q8Ar1iwb-VrP",
    "outputId": "43f2aa19-52d2-4c9d-f89c-4176a0491577"
   },
   "outputs": [],
   "source": [
    "twitter_df.columns = ['label', 'id', 'date', 'query', 'user_id', 'comment']\n",
    "twitter_df.drop(columns=['id', 'date', 'query', 'user_id'], inplace=True)\n",
    "twitter_df.dropna(inplace=True)\n",
    "twitter_df['label'] = pd.to_numeric(twitter_df['label'], errors='coerce')\n",
    "twitter_df['label'] = twitter_df['label'].map({0: 0, 4: 1})\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1746119518808,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "01869296765867302633"
     },
     "user_tz": -60
    },
    "id": "7k3eHOgIBkaF",
    "outputId": "ed2a4f83-5607-4b03-a2f4-468fe8a04f3d"
   },
   "outputs": [],
   "source": [
    "twitter_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LcAFEwcavFda"
   },
   "outputs": [],
   "source": [
    "# Load spaCy model and stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "# Text Cleaning\n",
    "def handle_negation(text):\n",
    "  negation_words = [\"not\", \"n't\", \"no\"]\n",
    "  words = text.split()\n",
    "  negated = False\n",
    "  result = []\n",
    "  for i, word in enumerate(words):\n",
    "    if word in negation_words:\n",
    "      negated = True\n",
    "    elif negated and word not in negation_words and not word.endswith('_NEG'):\n",
    "      result.append(word + '_NEG')\n",
    "      negated = False\n",
    "    else:\n",
    "      result.append(word)\n",
    "      negated = False\n",
    "  return \" \".join(result)\n",
    "\n",
    "def clean_text(text):\n",
    "  text = emoji.demojize(text, delimiters=(\"\", \"\"))\n",
    "  text = text.lower()\n",
    "  text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "  text = re.sub(r\"@\\w+|#\\w+\", '', text)\n",
    "  text = re.sub(r\"[^\\w\\s]\", '', text)\n",
    "  text = re.sub(r\"\\s+\", ' ', text).strip()\n",
    "  text = fix_contractions(text)\n",
    "  doc = nlp(text)\n",
    "  tokens = [token.lemma_ for token in doc if token.text not in stopwords and not token.is_space]\n",
    "  processed_text = \" \".join(tokens)\n",
    "  processed_text = handle_negation(processed_text)\n",
    "  return processed_text\n",
    "\n",
    "def preprocess_dataframe(df, text_column):\n",
    "  df[text_column] = df[text_column].astype(str).apply(clean_text)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwErrNTI4eK5"
   },
   "outputs": [],
   "source": [
    "# Sarcasm Detection Model (Logistic Regression)\n",
    "def train_sarcasm_model(df, model_out_path, vectorizer_out_path):\n",
    "  X, y = df['comment'], df['label']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "  tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "  X_train_vec = tfidf.fit_transform(X_train)\n",
    "  X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "  clf = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
    "  param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "  grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1')\n",
    "  grid_search.fit(X_train_vec, y_train)\n",
    "  clf_tuned = grid_search.best_estimator_\n",
    "  y_pred = clf_tuned.predict(X_test_vec)\n",
    "  y_pred_proba = clf_tuned.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "  print(\"Sarcasm Detection Report (Logistic Regression):\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "  print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "  joblib.dump(clf_tuned, model_out_path)\n",
    "  joblib.dump(tfidf, vectorizer_out_path)\n",
    "  return clf_tuned, tfidf, X_test, y_test, y_pred\n",
    "\n",
    "# Sarcasm Detection Model (Naive Bayes)\n",
    "def train_sarcasm_model_nb(df, model_out_path=\"sarcasm_model_nb.pkl\", vectorizer_out_path=\"sarcasm_vectorizer_nb.pkl\"):\n",
    "  X, y = df['comment'], df['label']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "  vectorizer = CountVectorizer()\n",
    "  X_train_vec = vectorizer.fit_transform(X_train)\n",
    "  X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "  clf = MultinomialNB()\n",
    "  clf.fit(X_train_vec, y_train)\n",
    "  y_pred = clf.predict(X_test_vec)\n",
    "  y_pred_proba = clf.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "  print(\"Sarcasm Detection Report (Naive Bayes Baseline):\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "\n",
    "  joblib.dump(clf, model_out_path)\n",
    "  joblib.dump(vectorizer, vectorizer_out_path)\n",
    "  return clf, vectorizer, X_test, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oV2Kblnd4p-W"
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis Model (Logistic Regression)\n",
    "def train_sentiment_model(df, sarcasm_model_path=None, vectorizer_path=None, model_out_path=\"sentiment_model.pkl\"):\n",
    "  X, y = df['comment'], df['label']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "  if sarcasm_model_path and vectorizer_path:\n",
    "    sarcasm_model = joblib.load(sarcasm_model_path)\n",
    "    sarcasm_vectorizer = joblib.load(vectorizer_path)\n",
    "    sarcasm_features = sarcasm_vectorizer.transform(X_train)\n",
    "    sarcasm_preds_train = sarcasm_model.predict(sarcasm_features)\n",
    "    X_train = pd.Series(sarcasm_preds_train.astype(str) + \" \" + X_train)\n",
    "    sarcasm_features_test = sarcasm_vectorizer.transform(X_test)\n",
    "    sarcasm_preds_test = sarcasm_model.predict(sarcasm_features_test)\n",
    "    X_test = pd.Series(sarcasm_preds_test.astype(str) + \" \" + X_test)\n",
    "\n",
    "  tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
    "  X_train_vec = tfidf.fit_transform(X_train)\n",
    "  X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "  clf = LogisticRegression(solver='liblinear', random_state=42, class_weight='balanced')\n",
    "  param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "  grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='f1')\n",
    "  grid_search.fit(X_train_vec, y_train)\n",
    "  clf_tuned = grid_search.best_estimator_\n",
    "  y_pred = clf_tuned.predict(X_test_vec)\n",
    "  y_pred_proba = clf_tuned.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "  print(\"Sentiment Analysis Report (Logistic Regression):\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "  print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "  joblib.dump(clf_tuned, model_out_path)\n",
    "  joblib.dump(tfidf, model_out_path.replace(\".pkl\", \"_vectorizer.pkl\"))\n",
    "  return clf_tuned, tfidf, X_test, y_test, y_pred\n",
    "\n",
    "\n",
    "# Sentiment Analysis Model (Naive Bayes)\n",
    "def train_sentiment_model_nb(df, sarcasm_model_path=None, vectorizer_path=None, model_out_path=\"sentiment_model_nb.pkl\"):\n",
    "  X, y = df['comment'], df['label']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "  # If sarcasm model and vectorizer provided, use sarcasm predictions as features\n",
    "  if sarcasm_model_path and vectorizer_path:\n",
    "    sarcasm_model = joblib.load(sarcasm_model_path)\n",
    "    sarcasm_vectorizer = joblib.load(vectorizer_path)\n",
    "\n",
    "    # Transform and predict sarcasm for train and test sets\n",
    "    sarcasm_features_train = sarcasm_vectorizer.transform(X_train)\n",
    "    sarcasm_preds_train = sarcasm_model.predict(sarcasm_features_train)\n",
    "    X_train = pd.Series(sarcasm_preds_train.astype(str) + \" \" + X_train)\n",
    "\n",
    "    sarcasm_features_test = sarcasm_vectorizer.transform(X_test)\n",
    "    sarcasm_preds_test = sarcasm_model.predict(sarcasm_features_test)\n",
    "    X_test = pd.Series(sarcasm_preds_test.astype(str) + \" \" + X_test)\n",
    "\n",
    "  # Vectorization and model training\n",
    "  vectorizer = CountVectorizer()\n",
    "  X_train_vec = vectorizer.fit_transform(X_train)\n",
    "  X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "  clf = MultinomialNB()\n",
    "  clf.fit(X_train_vec, y_train)\n",
    "  y_pred = clf.predict(X_test_vec)\n",
    "  y_pred_proba = clf.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "  print(\"Sentiment Analysis Report (Naive Bayes with Sarcasm Feature):\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "\n",
    "  joblib.dump(clf, model_out_path)\n",
    "  joblib.dump(vectorizer, model_out_path.replace(\".pkl\", \"_vectorizer.pkl\"))\n",
    "  return clf, vectorizer, X_test, y_test, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PkRV5i4h49-J"
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis Model (BERT)\n",
    "def train_bert_sentiment_model(df, model_name=\"bert-base-uncased\", model_out_path=\"bert_sentiment_model\", epochs=3, batch_size=16, max_length=128):\n",
    "  X, y = df['comment'], df['label']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "  y_train = y_train.astype(int)\n",
    "  y_test = y_test.astype(int)\n",
    "\n",
    "  tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "  train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "  test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).shuffle(1000).batch(batch_size)\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(batch_size)\n",
    "\n",
    "  model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "  steps_per_epoch = len(train_dataset)\n",
    "  num_train_steps = steps_per_epoch * epochs\n",
    "  optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=num_train_steps)\n",
    "\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "  history = model.fit(train_dataset, epochs=epochs, validation_data=test_dataset)\n",
    "  model.save_pretrained(model_out_path)\n",
    "  tokenizer.save_pretrained(model_out_path)\n",
    "\n",
    "  y_pred_logits = model.predict(test_dataset).logits\n",
    "  y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "  print(f\"BERT Sentiment Analysis Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_logits[:, 1]))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "\n",
    "  return model, tokenizer, history, X_test, y_test, y_pred\n",
    "\n",
    "\n",
    "#Sentiment Analysis Model (roBERTa)\n",
    "def train_roberta_sentiment_model(df, model_name=\"roberta-base\", model_out_path=\"roberta_sentiment_model\", epochs=3, batch_size=32, max_length=128):\n",
    "  # Split data\n",
    "  X, y = df['comment'], df['label'].astype(int)\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "  # Tokenization\n",
    "  tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "  train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "  test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=max_length, return_tensors='tf')\n",
    "\n",
    "  # Prepare datasets\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), y_train)).shuffle(1000).batch(batch_size)\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), y_test)).batch(batch_size)\n",
    "\n",
    "  # Load model\n",
    "  model = TFRobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "  # Optimizer setup with learning rate schedule\n",
    "  steps_per_epoch = len(train_dataset)\n",
    "  num_train_steps = steps_per_epoch * epochs\n",
    "  optimizer, lr_schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=num_train_steps)\n",
    "\n",
    "  # Compile model\n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "  # Train the model\n",
    "  history = model.fit(train_dataset, validation_data=test_dataset, epochs=epochs)\n",
    "\n",
    "  # Save model & tokenizer\n",
    "  model.save_pretrained(model_out_path)\n",
    "  tokenizer.save_pretrained(model_out_path)\n",
    "\n",
    "  # Predict and evaluate\n",
    "  y_pred_logits = model.predict(test_dataset).logits\n",
    "  y_pred = np.argmax(y_pred_logits, axis=1)\n",
    "\n",
    "  print(\"RoBERTa Sentiment Analysis Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_logits[:, 1]))\n",
    "  print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "  print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "\n",
    "  return model, tokenizer, history, X_test, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYBjarsz5Cho"
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis (LSTM)\n",
    "def train_lstm_model(df, use_sarcasm=False, sarcasm_model_path=None, vectorizer_path=None, model_out_path = \"lstm_sentiment_model.keras\", max_len=100, num_words=10000, embedding_dim=100, lstm_units=128, dropout_rate=0.5, epochs=10, batch_size=32, learning_rate=0.001):\n",
    "  X, y = df['comment'], df['label']\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "  if use_sarcasm and sarcasm_model_path and vectorizer_path:\n",
    "    sarcasm_model = joblib.load(sarcasm_model_path)\n",
    "    sarcasm_vectorizer = joblib.load(vectorizer_path)\n",
    "    sarcasm_features = sarcasm_vectorizer.transform(X_train)\n",
    "    sarcasm_preds_train = sarcasm_model.predict(sarcasm_features)\n",
    "    X_train = pd.Series(sarcasm_preds_train.astype(str) + \" \" + X_train)\n",
    "    sarcasm_features_test = sarcasm_vectorizer.transform(X_test)\n",
    "    sarcasm_preds_test = sarcasm_model.predict(sarcasm_features_test)\n",
    "    X_test = pd.Series(sarcasm_preds_test.astype(str) + \" \" + X_test)\n",
    "\n",
    "  tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "  tokenizer.fit_on_texts(X_train)\n",
    "  X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "  X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "  X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "  X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_len))\n",
    "  model.add(Bidirectional(LSTM(lstm_units, return_sequences=False)))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  optimizer = Adam(learning_rate=learning_rate)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy', 'precision', 'recall'])\n",
    "  model.summary()\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "  history = model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "  model.save(model_out_path)\n",
    "  joblib.dump(tokenizer, model_out_path.replace(\".keras\", \"_tokenizer.keras\"))\n",
    "\n",
    "  y_pred_proba = model.predict(X_test_pad)\n",
    "  y_pred = np.round(y_pred_proba)\n",
    "\n",
    "  print(\"LSTM Learning Model Evaluation Report:\")\n",
    "  print(classification_report(y_test, y_pred))\n",
    "  print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "  print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "  print(\"AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "\n",
    "\n",
    "  return model, tokenizer, history, X_test, y_test, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hmGTqYQ0lN_U"
   },
   "outputs": [],
   "source": [
    "# Qualitative Analysis\n",
    "def perform_qualitative_analysis(X_test, y_test, y_pred, n=10):\n",
    "  print(\"\\nQualitative Analysis (Examples of Correct and Incorrect Predictions)\")\n",
    "\n",
    "  y_test_array = np.array(y_test)\n",
    "  y_pred_array = np.array(y_pred)\n",
    "\n",
    "  correct_indices = np.where(y_test_array == y_pred_array)[0]\n",
    "  incorrect_indices = np.where(y_test_array != y_pred_array)[0]\n",
    "\n",
    "  get_text = X_test.iloc if isinstance(X_test, pd.Series) else X_test\n",
    "  get_label = y_test.iloc if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "  print(f\"\\n {min(n, len(correct_indices))} Correct Predictions\")\n",
    "  for i in np.random.choice(correct_indices, min(n, len(correct_indices)), replace=False):\n",
    "    print(f\"Actual: {get_label[i]}, Predicted: {y_pred_array[i]}, Text: {get_text[i]}\")\n",
    "\n",
    "  print(f\"\\n {min(n, len(incorrect_indices))} Incorrect Predictions\")\n",
    "  for i in np.random.choice(incorrect_indices, min(n, len(incorrect_indices)), replace=False):\n",
    "    print(f\"Actual: {get_label[i]}, Predicted: {y_pred_array[i]}, Text: {get_text[i]}\")\n",
    "\n",
    "def explain_with_lime(model, model_type, X_text, index=0, tokenizer=None, vectorizer=None, max_len=100):\n",
    "  class_names = ['Negative', 'Positive']\n",
    "  explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "  text_instance = X_text.iloc[index] if hasattr(X_text, 'iloc') else X_text[index]\n",
    "\n",
    "  # Define prediction function based on model type\n",
    "  if model_type in ['logistic_regression', 'naive_bayes']:\n",
    "    def predict_fn(texts):\n",
    "      X_vect = vectorizer.transform(texts)\n",
    "      return model.predict_proba(X_vect)\n",
    "\n",
    "  elif model_type in ['bert', 'roberta']:\n",
    "    def predict_fn(texts):\n",
    "      encodings = tokenizer(list(texts), padding=True, truncation=True, return_tensors='tf')\n",
    "      outputs = model(encodings)\n",
    "      probs = tf.nn.softmax(outputs.logits, axis=1).numpy()\n",
    "      return probs\n",
    "\n",
    "  elif model_type == 'lstm':\n",
    "    def predict_fn(texts):\n",
    "      sequences = tokenizer.texts_to_sequences(texts)\n",
    "      padded = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "      probs = model.predict(padded)\n",
    "      return np.hstack([1 - probs, probs])\n",
    "\n",
    "  else:\n",
    "    raise ValueError(f\"Unsupported model_type: {model_type}\")\n",
    "\n",
    "    # Generate explanation\n",
    "  explanation = explainer.explain_instance(text_instance, predict_fn, num_features=10)\n",
    "  explanation.show_in_notebook(text=True)\n",
    "\n",
    "# WordCloud\n",
    "def show_wordcloud(data, title='Word Cloud', mask=None, color_map='viridis', max_words=200):\n",
    "  text = ' '.join(data)\n",
    "  wordcloud = WordCloud(width=800, height=400, background_color='white',\n",
    "                        stopwords=stopwords, mask=mask, colormap=color_map,\n",
    "                        max_words=max_words).generate(text)\n",
    "  plt.figure(figsize=(15, 7.5))\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.title(title, fontsize=20)\n",
    "  plt.show()\n",
    "\n",
    "def generate_sentiment_wordclouds(df, sentiment_column='label', text_column='comment'):\n",
    "  for sentiment in df[sentiment_column].unique():\n",
    "      subset = df[df[sentiment_column] == sentiment][text_column]\n",
    "      title = f\"Word Cloud for Sentiment: {sentiment}\"\n",
    "      show_wordcloud(subset, title=title)\n",
    "\n",
    "def generate_sarcasm_wordclouds(df, sarcasm_column='label', text_column='comment'):\n",
    "  for label in df[sarcasm_column].unique():\n",
    "      subset = df[df[sarcasm_column] == label][text_column]\n",
    "      title = f\"Word Cloud for Sarcasm Label: {label}\"\n",
    "      show_wordcloud(subset, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZFrW0117Kgq"
   },
   "outputs": [],
   "source": [
    "def perform_ablation_studies_lstm(df, max_len=100, num_words=10000, embedding_dim=100, lstm_units=128, epochs=5, batch_size=32, sarcasm_model_path=None, sarcasm_vectorizer_path=None):\n",
    "  results = []\n",
    "\n",
    "  def preprocess_text(X_raw, add_sarcasm=False):\n",
    "    X = deepcopy(X_raw)\n",
    "    if add_sarcasm and sarcasm_model_path and sarcasm_vectorizer_path:\n",
    "      sarcasm_model = joblib.load(sarcasm_model_path)\n",
    "      sarcasm_vectorizer = joblib.load(sarcasm_vectorizer_path)\n",
    "      sarcasm_preds = sarcasm_model.predict(sarcasm_vectorizer.transform(X))\n",
    "      X = pd.Series(sarcasm_preds.astype(str) + \" \" + X)\n",
    "    return X\n",
    "\n",
    "  def build_and_evaluate(model_fn, label, use_sarcasm):\n",
    "    # Preprocess\n",
    "    X_raw, y = df['comment'], df['label']\n",
    "    X_train_raw, X_test_raw, y_train, y_test = train_test_split(X_raw, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    X_train = preprocess_text(X_train_raw, add_sarcasm=use_sarcasm)\n",
    "    X_test = preprocess_text(X_test_raw, add_sarcasm=use_sarcasm)\n",
    "\n",
    "    # Tokenize\n",
    "    tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    # Train\n",
    "    model = model_fn()\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    start = time.time()\n",
    "    model.fit(X_train_pad, y_train, validation_data=(X_test_pad, y_test), epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # Evaluate\n",
    "    y_probs = model.predict(X_test_pad).flatten()\n",
    "    y_pred = np.round(y_probs)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "    suffix = \" (with sarcasm)\" if use_sarcasm else \" (baseline)\"\n",
    "    print(f\"\\n{label + suffix}\")\n",
    "    print(f\"Time: {elapsed:.2f}s | Accuracy: {acc:.4f} | AUC: {auc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": label + suffix,\n",
    "        \"Accuracy\": acc,\n",
    "        \"AUC\": auc,\n",
    "        \"Time (s)\": elapsed\n",
    "        })\n",
    "\n",
    "  # Define models\n",
    "  model_variants = [\n",
    "      (\"Baseline LSTM\", lambda: Sequential([\n",
    "          Embedding(num_words, embedding_dim, input_length=max_len),\n",
    "          LSTM(lstm_units),\n",
    "          Dense(1, activation='sigmoid')\n",
    "      ])),\n",
    "      (\"LSTM with Dropout\", lambda: Sequential([\n",
    "          Embedding(num_words, embedding_dim, input_length=max_len),\n",
    "          LSTM(lstm_units, dropout=0.3, recurrent_dropout=0.3),\n",
    "          Dense(1, activation='sigmoid')\n",
    "        ])),\n",
    "      (\"Bidirectional LSTM\", lambda: Sequential([\n",
    "          Embedding(num_words, embedding_dim, input_length=max_len),\n",
    "          Bidirectional(LSTM(lstm_units)),\n",
    "          Dense(1, activation='sigmoid')\n",
    "      ])),\n",
    "      (\"LSTM without Embedding\", lambda: Sequential([\n",
    "          Input(shape=(max_len,)),\n",
    "          Reshape((max_len, 1)),\n",
    "          LSTM(lstm_units),\n",
    "          Dense(1, activation='sigmoid')\n",
    "      ])),\n",
    "      (\"LSTM with Smaller Units\", lambda: Sequential([\n",
    "          Embedding(num_words, embedding_dim, input_length=max_len),\n",
    "          LSTM(64),\n",
    "          Dense(1, activation='sigmoid')\n",
    "      ]))\n",
    "  ]\n",
    "\n",
    "  # Evaluate each model with and without sarcasm\n",
    "  for label, model_fn in model_variants:\n",
    "      build_and_evaluate(model_fn, label, use_sarcasm=False)\n",
    "      build_and_evaluate(model_fn, label, use_sarcasm=True)\n",
    "\n",
    "  # Plot results\n",
    "  results_df = pd.DataFrame(results).set_index(\"Model\")\n",
    "  results_df[[\"Accuracy\", \"AUC\"]].plot(kind=\"bar\", figsize=(12, 6), ylim=(0, 1), colormap=\"viridis\")\n",
    "  plt.title(\"Model Comparison: Accuracy and AUC\")\n",
    "  plt.ylabel(\"Score\")\n",
    "  plt.xticks(rotation=45, ha='right')\n",
    "  plt.grid(True)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  results_df[\"Time (s)\"].plot(kind=\"bar\", figsize=(10, 4), color=\"salmon\")\n",
    "  plt.title(\"Training Time per Model\")\n",
    "  plt.ylabel(\"Seconds\")\n",
    "  plt.xticks(rotation=45, ha='right')\n",
    "  plt.grid(True)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NVusn0YCbN-y"
   },
   "outputs": [],
   "source": [
    "# Preprocessing models\n",
    "reddit_df_preprocessed = preprocess_dataframe(reddit_df, 'comment')\n",
    "reddit_df_preprocessed.to_csv('reddit_df_preprocessed.csv', index=False)\n",
    "\n",
    "twitter_df_preprocessed = preprocess_dataframe(twitter_df, 'comment')\n",
    "twitter_df_preprocessed.to_csv('twitter_df_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M4XJ-ZJKYClG"
   },
   "outputs": [],
   "source": [
    "reddit_df_preprocessed = pd.read_csv('reddit_df_preprocessed.csv')\n",
    "twitter_df_preprocessed = pd.read_csv('twitter_df_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dptHqLTDoG7"
   },
   "outputs": [],
   "source": [
    "reddit_df_preprocessed.dropna(inplace=True)\n",
    "reddit_df_preprocessed = reddit_df_preprocessed.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "twitter_df_preprocessed.dropna(inplace=True)\n",
    "twitter_df_preprocessed = twitter_df_preprocessed.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 235492,
     "status": "ok",
     "timestamp": 1746370130840,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "GuoQ4gzk8rOw",
    "outputId": "67534d4a-b5ec-4fb3-a6af-7e3b2364bbeb"
   },
   "outputs": [],
   "source": [
    "#Sarcasm model (Logistic Regression/TF-IDF)\n",
    "sarcasm_clf, sarcasm_tfidf, X_test_sarcasm, y_test_sarcasm, y_pred_sarcasm_lr = train_sarcasm_model(reddit_df_preprocessed, 'sarcasm_model.pkl', 'sarcasm_vectorizer.pkl')\n",
    "perform_qualitative_analysis(X_test_sarcasm, y_test_sarcasm, y_pred_sarcasm_lr, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8513,
     "status": "ok",
     "timestamp": 1746356626391,
     "user": {
      "displayName": "anjum hameed",
      "userId": "11712047490420187466"
     },
     "user_tz": -60
    },
    "id": "FnEI8oWKO2DH",
    "outputId": "32e93e0e-b1b3-4518-fb43-785a5d1f734c"
   },
   "outputs": [],
   "source": [
    "#Sarcasm model (Naive Bayes)\n",
    "sarcasm_clf_nb, sarcasm_vectorizer_nb, X_test_sarcasm_nb, y_test_sarcasm_nb, y_pred_sarcasm_nb = train_sarcasm_model_nb(reddit_df_preprocessed, 'sarcasm_model_nb.pkl', 'sarcasm_vectorizer_nb.pkl')\n",
    "perform_qualitative_analysis(X_test_sarcasm_nb, y_test_sarcasm_nb, y_pred_sarcasm_nb, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 429503,
     "status": "ok",
     "timestamp": 1746381442541,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "5_5pbnfvzhnP",
    "outputId": "b4a710d5-be42-4b0c-bbb3-22aefe298a3f"
   },
   "outputs": [],
   "source": [
    "#Sentiment model (Logistic Regression / TF-IDF)\n",
    "clf_lr, vectorizer_lr, X_test_lr, y_test_lr, y_pred_lr = train_sentiment_model(twitter_df_preprocessed, sarcasm_model_path=None, vectorizer_path=None, model_out_path=\"sentiment_model_lr.pkl\")\n",
    "perform_qualitative_analysis(X_test_lr, y_test_lr, y_pred_lr, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 477880,
     "status": "ok",
     "timestamp": 1746357540043,
     "user": {
      "displayName": "anjum hameed",
      "userId": "11712047490420187466"
     },
     "user_tz": -60
    },
    "id": "dYsQQ8dszvMf",
    "outputId": "a4db1980-06a2-4c51-d42d-dbb4f0b78c14"
   },
   "outputs": [],
   "source": [
    "#Sentiment model with sarcasm (Logistic Regression / TF-IDF)\n",
    "clf_lr_sarc, vectorizer_lr_sarc, X_test_lr_sarc, y_test_lr_sarc, y_pred_lr_sarc = train_sentiment_model(twitter_df_preprocessed, sarcasm_model_path=\"sarcasm_model.pkl\", vectorizer_path=\"sarcasm_vectorizer.pkl\", model_out_path=\"sentiment_model_lr_sarcasm.pkl\")\n",
    "perform_qualitative_analysis(X_test_lr_sarc, y_test_lr_sarc, y_pred_lr_sarc, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17696,
     "status": "ok",
     "timestamp": 1746357557743,
     "user": {
      "displayName": "anjum hameed",
      "userId": "11712047490420187466"
     },
     "user_tz": -60
    },
    "id": "LLgoyugJ-7x5",
    "outputId": "288518cd-67b7-4b6b-ba2a-5275218f5760"
   },
   "outputs": [],
   "source": [
    "# Sentiment model (Naive Bayes)\n",
    "clf_nb, vectorizer_nb, X_test_nb, y_test_nb, y_pred_nb = train_sentiment_model_nb(twitter_df_preprocessed, model_out_path=\"sentiment_model_nb.pkl\")\n",
    "perform_qualitative_analysis(X_test_nb, y_test_nb, y_pred_nb, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26931,
     "status": "ok",
     "timestamp": 1746357591556,
     "user": {
      "displayName": "anjum hameed",
      "userId": "11712047490420187466"
     },
     "user_tz": -60
    },
    "id": "f89pxciF-4RM",
    "outputId": "adbd485e-68f9-4b91-90ad-94ef71782152"
   },
   "outputs": [],
   "source": [
    "#Sentiment model with sarcasm (Naive Bayes)\n",
    "clf_nb_sarc, vectorizer_nb_sarc, X_test_nb_sarc, y_test_nb_sarc, y_pred_nb_sarc = train_sentiment_model_nb(twitter_df_preprocessed, sarcasm_model_path=\"sarcasm_model_nb.pkl\", vectorizer_path=\"sarcasm_vectorizer_nb.pkl\", model_out_path=\"sentiment_nb_sarcasm.pkl\")\n",
    "perform_qualitative_analysis(X_test_nb_sarc, y_test_nb_sarc, y_pred_nb_sarc, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnO0C5LJyuD8"
   },
   "outputs": [],
   "source": [
    "#Reduce dataset to 5% of size (40,000 rows)\n",
    "twitter_df_preprocessed = twitter_df_preprocessed.sample(frac=0.05, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "75be585087e942c79b1c36ebbb9686c2",
      "884f69bd41fc4b458c11c27041aa3b18",
      "6da45e59d715489484ca1fdbc018c8b5",
      "0e70c191e3b3445e83a073f3200d1d8e",
      "0534c7c7e4ff447bac2d1b39226adb18",
      "8088cf7f43b745d09985ec9482b67a2a",
      "563870b57008400a9cf7aae4992832f5",
      "a9479e12aea14cf591ac81bf672f80b7",
      "eb90cc41fec9435180c5db0fceb36563",
      "d40f58fb3c714e4287fa6eacae8b1af6",
      "9651edee21a149818414ba9968ebcf90",
      "525a9a5c5d0e487b8f46bb3dceca15ab",
      "a95d2a1ee1df4968a11fcb5eec7fdd01",
      "1c124f0fbf4e4cdd940af9a0329eedf9",
      "b640c5e15f98457db9846863aa1d385c",
      "2efcce48808f414a803ed1d45b06bfca",
      "878cc090f15349ac98676330fb730118",
      "2c90d9bfd7b94169ac10064282931d91",
      "7d42384af76647028684fdba42de330e",
      "4dce7e5ea2f54ec5930c4f800e894676",
      "ab6f4f889dc84762868c0f8651434731",
      "7347c927bbd24c818c25a45c260c3ea4",
      "3d0b3309394e43feadac889f3f3f910f",
      "a8f40323ac384eaa8fd4c8c417424ac3",
      "9f60c93e34fb45c2896455af79d290a3",
      "65d52c84cfc84ad0b1200a7a862cf217",
      "f1662cb566f2469cb7ae17acd9cbdbd8",
      "f3d40a694a644cc7a490210788612eff",
      "8c63561d33a74848bd7ec82d365e742d",
      "43d48c84e0084aa2b536272b536ba4ca",
      "235cb16ec7cb4db98b6799a3afc832de",
      "3dadb4c285f547b1bf5a01f0e6c6666f",
      "958c513934c44a36a51af68d9318dcea",
      "a552ffb51f104d28b7e919f0e01aaa9e",
      "7a7449341b4045328e649e2128165a28",
      "d839ad3472264852b5e684ca9c88dfc1",
      "3bc2b1534b9348b782a1e2dc5d194a66",
      "b7cd014c44de428cb9e3a24ca0c1a7c5",
      "f26fc13be44540e586f89019fd63f8c6",
      "01e0b7e15e064ffab5ba6ddfcbfbec80",
      "b9204361367a42068977ed82e0c83994",
      "0f34f27f480f48adad6c0e166eefffc6",
      "408d0d7a2b7747e68d8f66f6e23350ae",
      "0314be562de04387a26fe0be4cb3762b",
      "75ed20fb00094643a6af24a5b0187c20",
      "ebaa97b2b01548858508880724ff76de",
      "8138e54c76814b739f7d6c6fe4d258cb",
      "20d4d417dc91480b9a115fe4a4a4534e",
      "1086840e44374ad7939aa4a371d67080",
      "dcc892cd85a64f04ace237538db9e960",
      "fff3889755a1492ea3cf72cba0572f36",
      "db1fce6fe58a4a02b3774c197453c59b",
      "440fae2d6f8343b1971a742e5e8aa108",
      "a996825f2e1543bcbf09e32246664b05",
      "c12f046257014a99b0d89e7904c998b8"
     ]
    },
    "executionInfo": {
     "elapsed": 2627258,
     "status": "ok",
     "timestamp": 1746376985409,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "QjAqwFXN_GlA",
    "outputId": "21192f51-7603-44c1-c965-f2ef46e40c9e"
   },
   "outputs": [],
   "source": [
    "# Deep Learning sentiment model (BERT)\n",
    "with tf.device('/GPU:0'):\n",
    "  bert_model, bert_tokenizer, bert_history, X_test_bert, y_test_bert, y_pred_bert = train_bert_sentiment_model(twitter_df_preprocessed, model_out_path='bert_sentiment_model')\n",
    "  perform_qualitative_analysis(X_test_bert, y_test_bert, y_pred_bert, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8be7aa3f85454acc8a97c17640c34d23",
      "8dbb0e4af01747d296ba090319a36bb0",
      "396390b10e3d46a78791b58e072d8632",
      "86e2a1a46fdd4cb5a3bd8ad23595d47f",
      "740239db645649a6b4849bd28ee50cb1",
      "9851bebfb330417fb44f7e852f34c428",
      "f571fc5e03ac4688bca9ce218e9b456a",
      "8ca3d5eddb344c08bed80718c4799fef",
      "faf8c8bc90e640fdb7ae3f9e5a7a5231",
      "f2f7eccc072b40a48a0796d1b70f214c",
      "5a885a14860148839260030578de2113",
      "70a3afe287d1474b909862c1ba7e18a2",
      "e13f3b70b0dc441a88b4242b8f1680df",
      "0a3010cb984243efbdeac2838a66f76f",
      "69913f383ffb4ef9bd223ab430094b5d",
      "6b26489f867345e591cae4cbe2db66c6",
      "feddb057c698436ebd09fa7ae2e228bb",
      "67138a3b7c8c4ca58522933530442373",
      "5b7fc5524074431790d5298dbfb33a36",
      "e51ecc68959f42d49f849fd06ad9d418",
      "e4550be24f9d45eeb3c0b5b7837db326",
      "f40616806a2047258a5afb52842d97ea",
      "b8909b76bbcb408795757e45b42bec75",
      "02fccb4e3b704c35965c9d6892272332",
      "1237e97245af49fa87fe277701d9f350",
      "6d052c6b6a5e415cac7a8a047e47b334",
      "b7e793d04cc841c1bbebb206860d5f83",
      "198a627fdd3240e391695f1e735061ba",
      "92ec7acb4d214396a53a33dab07e0322",
      "1d3df231e85b4e83bbf90a65b1eeeaf4",
      "06d12392ec5f4a808f5517e60ee9c79a",
      "faa44ad0e29f4416adbb11ef3a23b6ed",
      "82f94a6e2165434eae53e6a8d3a28ea2",
      "113bb3da3c2d453e88405ee3d964c05e",
      "75ada8816dfb49a2a63338853b07ac88",
      "5c5a1dabc1b74cd3b43876d03f012786",
      "37907af976b447c09ab8dc9d32129e8f",
      "7c2b2efd429f4fe49400f4ab41d190ce",
      "baceeb3f0c324e47b73e1d8e745dc538",
      "76a6d256396249db83812127ef838bb7",
      "3e1f9372a6da49468003edabe064e0b2",
      "2fa85154c418490e994f99825d8ab118",
      "b2e58664a2af4c929f5dc6f94e2e2313",
      "28c8a87fbe3543a59256daf37bbf70d4",
      "9003874f585e42f098e29a2d3da3f27a",
      "d28895c5142e4e6e9a337487355204de",
      "c3499afaed5243f486db7203a3a13e6f",
      "da7cba1fdab34e99a1ed1862c208d001",
      "5055a03251f740a892b9c126779e5c46",
      "81ebd6cafd334b6b818744f2b6c7f4e6",
      "f0508355d7764445829794eed14b63a3",
      "5d4ae431ac5b405890be9b3ba1fcdb3d",
      "21d907903eb647fbbe02110a6276cd3b",
      "b6400111729e4ec19f6b89479c594be7",
      "1d379d48be0a4115a795ff4681a79f03",
      "a24f457f7ba448d0be2838fcb60433d9",
      "ab51e3c6113143638593f9b80bcad663",
      "977b215a82b24bbfb58185e49be6787c",
      "452b9a3174a94f41aa69e7210074b77f",
      "77c80d51afb742d391e31eb5179acd51",
      "f47cb41882d24ea39433c221832dee05",
      "2227cc3c24a04acea4322f511a1d6284",
      "c510790ffdc549608cc8a7fed6212efd",
      "ca685fcbed5042a99b2cd92845f5b65c",
      "96e47bdd44ca4a3eacf1d75d49f3f38f",
      "53b4578432894ebd835a46a59db633ad"
     ]
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2747338,
     "status": "ok",
     "timestamp": 1746379732773,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "ADzzdt8QbeFk",
    "outputId": "3f02e306-62a4-4c99-8ba1-e267aeb3edc1"
   },
   "outputs": [],
   "source": [
    "# Deep Learning sentiment model (roBERTa)\n",
    "with tf.device('/GPU:0'):\n",
    "  roberta_model, roberta_tokenizer, roberta_history, X_test_roberta, y_test_roberta, y_pred_roberta = train_roberta_sentiment_model(twitter_df_preprocessed, model_name=\"roberta-base\", model_out_path=\"roberta_sentiment_model\", epochs=3, batch_size=16, max_length=128)\n",
    "  perform_qualitative_analysis(X_test_roberta, y_test_roberta, y_pred_roberta, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 88687,
     "status": "ok",
     "timestamp": 1746380667581,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "obUFP_J9C_4s",
    "outputId": "9079c96e-85fe-4d8a-eff8-13699e549510"
   },
   "outputs": [],
   "source": [
    "# Deep Learning sentiment model (LSTM)\n",
    "with tf.device('GPU:0'):\n",
    "  lstm_model, lstm_tokenizer, lstm_history, X_test_lstm, y_test_lstm, y_pred_lstm = train_lstm_model(twitter_df_preprocessed, model_out_path = \"lstm_sentiment_model.keras\")\n",
    "  perform_qualitative_analysis(X_test_lstm, y_test_lstm, y_pred_lstm, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 92565,
     "status": "ok",
     "timestamp": 1746380760150,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "0tvar45Kbrdx",
    "outputId": "2919a110-825f-4540-8790-cc1b51e495a7"
   },
   "outputs": [],
   "source": [
    "# Deep Learning sentiment model with sarcasm (LSTM)\n",
    "with tf.device('GPU:0'):\n",
    "  lstm_model_sarc, lstm_tokenizer_sarc, lstm_history_sarc, X_test_lstm_sarc, y_test_lstm_sarc, y_pred_lstm_sarc = train_lstm_model(twitter_df_preprocessed, use_sarcasm=True, sarcasm_model_path='sarcasm_model.pkl', vectorizer_path='sarcasm_vectorizer.pkl', model_out_path='lstm_sentiment_sarc_model.h5')\n",
    "  perform_qualitative_analysis(X_test_lstm_sarc, y_test_lstm_sarc, y_pred_lstm_sarc, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99VDagCWDNCe"
   },
   "outputs": [],
   "source": [
    "with tf.device('GPU:0'):\n",
    "  perform_ablation_studies_lstm(twitter_df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3285,
     "status": "ok",
     "timestamp": 1746380845090,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "P6K2QZWrbo1W",
    "outputId": "e088204f-0bcb-4030-c17b-099f5c5ccc29"
   },
   "outputs": [],
   "source": [
    "# Word Clouds\n",
    "generate_sentiment_wordclouds(twitter_df_preprocessed, sentiment_column='label', text_column='comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 26041,
     "status": "ok",
     "timestamp": 1746380968358,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "HUwBX4wWaPBI",
    "outputId": "96fe7edd-099b-48a6-ca38-877d67d76b0b"
   },
   "outputs": [],
   "source": [
    "generate_sarcasm_wordclouds(reddit_df_preprocessed, sarcasm_column='label', text_column='comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15075,
     "status": "ok",
     "timestamp": 1746387065190,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "WCZxEhqNgKb5",
    "outputId": "eb46c8df-4f9e-45d7-b292-52232d24b6f2"
   },
   "outputs": [],
   "source": [
    "clf_lr = joblib.load(\"sentiment_model_lr.pkl\")\n",
    "vectorizer_lr = joblib.load(\"sentiment_model_lr_vectorizer.pkl\")\n",
    "\n",
    "lstm_model = load_model(\"lstm_sentiment_model.keras\")\n",
    "lstm_tokenizer = joblib.load(\"lstm_sentiment_model_tokenizer.keras\")\n",
    "\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert_sentiment_model\")\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert_sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 5811,
     "status": "ok",
     "timestamp": 1746382692415,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "XFkucc3bmxC3",
    "outputId": "d1a6485c-6780-488e-b3d7-2e76bed444c6"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "explain_with_lime(model=clf_lr,model_type='logistic_regression', X_text=X_test_lr, index=3, vectorizer=vectorizer_lr)\n",
    "\n",
    "# BERT\n",
    "explain_with_lime(model=bert_model, model_type='bert', X_text=X_test_bert, index=1, tokenizer=bert_tokenizer)\n",
    "\n",
    "# LSTM\n",
    "explain_with_lime(model=lstm_model, model_type='lstm', X_text=X_test_lstm, index=1, tokenizer=lstm_tokenizer, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkbrzwlPoNJp"
   },
   "outputs": [],
   "source": [
    "test_comments = [\"I love this product!\", \"Oh wow, another delay. Just what I needed.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1746382741949,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "hZq3Xix9zueE",
    "outputId": "0845eee7-eb34-4ca4-9aef-bdea03b7b2a6"
   },
   "outputs": [],
   "source": [
    "X_vec = vectorizer_lr.transform(test_comments)\n",
    "lr_preds = clf_lr.predict(X_vec)\n",
    "print(\"Logistic Regression predictions:\", lr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1746382744017,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "XnSVLSHCt3FG",
    "outputId": "201837a7-54b6-4d97-8abb-89d8a798d108"
   },
   "outputs": [],
   "source": [
    "inputs_bert = bert_tokenizer(test_comments, padding=True, truncation=True, max_length=128, return_tensors='tf')\n",
    "outputs_bert = bert_model(inputs_bert)\n",
    "bert_preds = tf.argmax(outputs_bert.logits, axis=1).numpy()\n",
    "print(\"BERT predictions:\", bert_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1746382745853,
     "user": {
      "displayName": "Affan Ahmed",
      "userId": "17523918992071307567"
     },
     "user_tz": -60
    },
    "id": "ODGnJNXRzDG6",
    "outputId": "c9f1db82-c8b0-41be-afcf-8ef5d0816502"
   },
   "outputs": [],
   "source": [
    "seqs = lstm_tokenizer.texts_to_sequences(test_comments)\n",
    "padded = pad_sequences(seqs, maxlen=100, padding='post', truncating='post')\n",
    "\n",
    "# Predict\n",
    "lstm_probs = lstm_model.predict(padded)\n",
    "lstm_preds = (lstm_probs > 0.5).astype(int).flatten()\n",
    "print(\"LSTM predictions:\", lstm_preds)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
